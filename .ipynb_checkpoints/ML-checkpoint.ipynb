{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fdd8b65",
   "metadata": {},
   "source": [
    "# Thesis Code Part 3: ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc1c01",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70bfa6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/bdrad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/bdrad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<negspacy.negation.Negex at 0x7efda27b8b50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scispacy\n",
    "import spacy\n",
    "from negspacy.negation import Negex\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# SpaCy model for biomedical processing\n",
    "nlp = spacy.load(\"en_core_sci_md\")\n",
    "nlp.add_pipe(\"negex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130ca05b",
   "metadata": {},
   "source": [
    "## Acquire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d30e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_val_dataset.csv')\n",
    "test_df = pd.read_csv('test_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe4bba",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe9f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from Chen & Sohn\n",
    "# https://colab.research.google.com/drive/1jp8Oi2s13g2B34SPjX5074FDBlhmUdgn?usp=sharing#scrollTo=MIA9a7rckKil\n",
    "def preprocess(nlp_model,input_text):\n",
    "    input_text = input_text.strip()\n",
    "    doc = nlp_model(input_text)\n",
    "    negation_list = [0]*len(doc)\n",
    "    tokens = list()\n",
    "    stop = set(stopwords.words('english')+list(string.punctuation))\n",
    "    stop.add(\"XXXX\")\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent._.negex:\n",
    "            index = ent.start\n",
    "            while index < ent.end:\n",
    "                negation_list[index] = 1\n",
    "                index += 1\n",
    "        \n",
    "    for i,token in enumerate(doc):\n",
    "        if str(token).lower() not in stop:\n",
    "            if negation_list[i] == 1:\n",
    "                tokens.append((\"NEGEX_\"+str(token).lower()))\n",
    "            else:\n",
    "                tokens.append(str(token).lower())\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9674ac2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "train_text = train_df[\"Caption\"].to_list()\n",
    "\n",
    "def token_generator(text_list):\n",
    "    for text in text_list:\n",
    "        yield preprocess(nlp,text)\n",
    "\n",
    "train_tokens = token_generator(train_text)\n",
    "train_vocab_dict = Dictionary(train_tokens)\n",
    "\n",
    "# gensim Dictionary does not create an id2token dictionary  until dictionary is called\n",
    "train_vocab_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79db71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test_df[\"Caption\"].to_list()\n",
    "test_tokens = token_generator(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c37c508",
   "metadata": {},
   "source": [
    "## Modeling - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5c8cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_vector_create(tuple_list,vocab_len):\n",
    "    #tuple_list will have data structure akin to gensim dictionary doc2bow output \n",
    "    sparse_vector = np.zeros(vocab_len)\n",
    "    for id,freq in tuple_list:\n",
    "        sparse_vector[id] = freq\n",
    "    return sparse_vector\n",
    "\n",
    "def sparse_vector_generator(tokens,vocab_dict,vocab_len):\n",
    "    for token in tokens:\n",
    "        yield sparse_vector_create(vocab_dict.doc2bow(token),vocab_len)\n",
    "\n",
    "# recreate generator object to reset it , otherwise will output empty result\n",
    "train_tokens = token_generator(train_text)\n",
    "x_train_sparse = [sparse_vector for sparse_vector in sparse_vector_generator(train_tokens,train_vocab_dict,len(train_vocab_dict))]\n",
    "y_train = train_df['comm'].to_list()\n",
    "y_test = test_df['comm'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6b15a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "nb_classifier = naive_bayes.MultinomialNB(alpha=1.0)\n",
    "\n",
    "nb_classifier.fit(x_train_sparse,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e44907a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = token_generator(test_text)\n",
    "nb_predictions = list()\n",
    "\n",
    "for token in test_tokens:\n",
    "    test_sparse_vector = sparse_vector_create(train_vocab_dict.doc2bow(token),len(train_vocab_dict))\n",
    "    nb_predictions.append(nb_classifier.predict(test_sparse_vector.reshape(1,-1))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefcd6ec",
   "metadata": {},
   "source": [
    "## Modeling - Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bcb4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer(use_idf=True, smooth_idf = True,sublinear_tf = True)\n",
    "tfidf.fit(x_train_sparse)\n",
    "x_train_tfidf= tfidf.transform(x_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c1c700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC(C=1.0,kernel ='linear')\n",
    "SVM.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f843431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = token_generator(test_text)\n",
    "svm_predictions = list()\n",
    "\n",
    "for token in test_tokens:\n",
    "    test_sparse_vector = sparse_vector_create(train_vocab_dict.doc2bow(token),len(train_vocab_dict))\n",
    "    x_test_tfidf = tfidf.transform(test_sparse_vector.reshape(1,-1))\n",
    "    svm_predictions.append(SVM.predict(x_test_tfidf)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707d657",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be946f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "class metric_calc:\n",
    "    def __init__(self, y,y_hat):\n",
    "        # y is true label, y_hat is predicted label\n",
    "        self.y_hat = y_hat\n",
    "        self.y = y\n",
    "        conf_matrix = metrics.confusion_matrix(y,y_hat)\n",
    "    \n",
    "        self.true_neg = conf_matrix[0][0]\n",
    "        self.false_pos = conf_matrix[0][1]\n",
    "        self.false_neg = conf_matrix[1][0]\n",
    "        self.true_pos = conf_matrix[1][1]\n",
    "        self.sum = self.true_pos + self.true_neg + self.false_pos + self.false_neg\n",
    "\n",
    "    def conf_matrix_values(self):\n",
    "        print(f\"TN: {self.true_neg}, FP: {self.false_pos}, FN: {self.false_neg} TP: {self.true_pos}\")\n",
    "    \n",
    "    def accuracy(self):\n",
    "        acc = (self.true_pos + self.true_neg)/self.sum\n",
    "        print(f\"Accuracy is {acc:.4f}\")\n",
    "\n",
    "    def sens_spec(self):\n",
    "        sens = self.true_pos/(self.true_pos+self.false_neg)\n",
    "        spec = self.true_neg/(self.true_neg+self.false_pos)\n",
    "        print(f\"Sensitivity (aka recall) is {sens:.4f}\")\n",
    "        print(f\"Specificity is {spec:.4f}\")\n",
    "\n",
    "    def incorrect_index(self):\n",
    "        # return indices of examples that are incorrectly predicted\n",
    "        index = list()\n",
    "        for i,label in enumerate(self.y):\n",
    "            if label != self.y_hat[i]:\n",
    "                index.append(i)\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5392df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "TN: 245, FP: 7, FN: 15 TP: 96\n",
      "Accuracy is 0.9394\n",
      "Sensitivity (aka recall) is 0.8649\n",
      "Specificity is 0.9722\n",
      "SVM\n",
      "TN: 250, FP: 2, FN: 4 TP: 107\n",
      "Accuracy is 0.9835\n",
      "Sensitivity (aka recall) is 0.9640\n",
      "Specificity is 0.9921\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes\")\n",
    "nb_metric = metric_calc(y_test,nb_predictions)\n",
    "nb_metric.conf_matrix_values()\n",
    "nb_metric.accuracy()\n",
    "nb_metric.sens_spec()\n",
    "\n",
    "print(\"SVM\")\n",
    "svm_metric = metric_calc(y_test,svm_predictions)\n",
    "svm_metric.conf_matrix_values()\n",
    "svm_metric.accuracy()\n",
    "svm_metric.sens_spec()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
